# 历时语料库(using关系型数据库)方案

吴先

wuxian94@pku.edu.cn

[TOC]

## 数据库引擎

关系型数据库软件在Linux上直接就选mysql了，没有做其他对比。

关于引擎，需要对比一下。业务具体的侧重点不同，适合的引擎也会不同。

|          | MyISAM                                                       | InnoDB                                                       |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 事务     | 不支持。                                                     | 自动打开AUTOCOMMIT，每条SQL语句会被封装成一个事务。          |
| 锁       | 只有表锁。                                                   | 支持行锁，所以适合大量同时查询与修改。                       |
| 外键     | 不支持。                                                     | 支持。                                                       |
| 全文索引 | 支持，然而不支持中文分词。                                   | 不支持。                                                     |
| 计数     | 整张表有一个计数器，所以count(*)效率很高。但是如果有where就与InnoDB一样了。 | 没有计数器，所有count()都是老老实实一行行做的。              |
| 文件构成 | 三个文件，分别是表定义、数据和索引。                         | 通常都在一个文件里。                                         |
| 主索引   | 非聚集索引，索引保存的是数据文件的指针。主键与辅助索引独立。 | 聚集索引。数据文件和索引在一起，通过主键索引效率很高。但是辅助索引要先索引到主键，再查询到数据。 |

通过对比，我们的业务不涉及频繁的写入或更新，而会涉及大量的查询和JOIN。而JOIN的效率很大程度上受索引的影响，所以高索引性能的MyISAM也更适合这个场景。至于不支持外键的缺点，我们可以通过手动记录键关系，在键上加Index，然后JOIN…ON...来实现。

因此目前所有的表都选择MyISAM作为数据库引擎。在后面的实践中也发现，大批量写入时MyISAM的性能远好于InnoDB。

至于数据库的编码，为了对字符集最大限度的兼容，采用UTF8MB4。

## 表和数据项设计

### 设计思路

首先考虑包含有哪些实体。以句子为单位存储，自然包含Sentence实体；Sentence要依附于Document存在，利用document_id和pos（position）来确定其相对位置。

因为我们的业务含有自定义的字符串检索，所以考虑通过自建倒排索引表来实现。因此要有InvertedIndex实体，至少需要token、sentence_id属性；为了实现相对位置的查询，要包含pos、start_offset和end_offset。因为有多种类型的倒排索引，本来想用type字段做标识，但是考虑到性能和后续修改的方便，直接分表，为不同的倒排索引建立不同的表。

其他的句子特征，不打算作为字段添加在Sentence表中，对于所有特征单独建表，通过sentence_id

### 表定义和数据项含义

#### Document

| 字段名 | 含义                         |
| ------ | ---------------------------- |
| id     | 自增主键                     |
| date   | 文档的日期                   |
| source | 来源                         |
| path   | 数据文件的路径（仅做记录用） |

#### Sentence

| 字段名          | 含义             |
| --------------- | ---------------- |
| id              | 自增主键         |
| content         | 内容             |
| part_of_speech  | 分词与词性标注   |
| pos             | 位于文档中的位置 |
| fk_document_id* | 所在文档的id外键 |

*：所有fk开头的字段代表外键的语义，需要与真实对象的id对应，并按需添加索引。

#### XXXInvertedIndex

| 字段名         | 含义                  |
| -------------- | --------------------- |
| id             | 自增主键              |
| token          | 词项                  |
| start_offset   | 位于句子中的起始偏移* |
| end_offset     | 位于句子中的结束偏移  |
| pos            | 位于句子中的位置      |
| fk_sentence_id | 所在句子的id外键      |

*：偏移是以字为单位的，位置以词为单位。

### 索引

fk_sentence_id@XXXInvertedIndex

token@XXXInvertedIndex

本来想在pos上也添加索引，但是目前看来还没有因为pos的检索导致性能瓶颈，所以暂时没放。

## 实践与性能调优

### 插入数据

在1986～1995年十年间的人民日报语料检验了一下设计和性能。

插入的句子总数为：

```mysql
select Document.path, cnt from
(select fk_document_id, count(*) as cnt from Sentence group by fk_document_id) t1
join
Document
on t1.fk_document_id=Document.id;
```

```
86cutwordfinal.txt	588650
87cutwordfinal.txt	535240
88cutwordfinal.txt	524758
89cutwordfinal.txt	456548
90cutwordfinal.txt	440165
91cutwordfinal.txt	490359
92cutwordfinal.txt	501704
93cutwordfinal.txt	552052
94cutwordfinal.txt	553401
95cutwordfinal.txt	818218
```

插入时一开始希望让插入脚本的行为是幂等的，所以在插入每个句子时校验了句子是否已存在于数据库中，但是导致了严重的性能问题。因为数据库的查询时间会随着表规模的增大呈对数增长（这时候还没加任何索引）。此时的插入效率大约是每处理1w行原语料，所需时间从空表开始，2分钟、3分钟、5分钟、7分钟……一直增长。

一开始以为是插入过程不断调整B+树引起的磁盘读写瓶颈。但是检查了机器的性能监控，并没有遇到瓶颈（CPU单核跑到100%很正常）。通过`show processlist;`查询发现，大部分时间都在做查询，因此意识到是前面的防重复的代码的锅。

然后关闭了查询，直接向表内插数据和倒排索引。如果插入时出了问题，不然索性删表重建更快。根据MySQL 5.7 Reference Manual——8.2.4.1 Optimizing INSERT Statements中的建议，增大了bulk_insert_buffer_size至256MB；自己写了将多个INSERT语句合并成一个INSERT的bulk_insert接口。最终的效率为15秒处理1w行数据，只进行句子的插入，不建倒排索引的话，大概1～2秒处理1w行，充分发挥了MyISAM引擎的能力。

### 检索数据

第一步先设计了检索一个给定词语的上下文的语句。思路是完全利用倒排索引实现。

在没加任何索引的数据库上先进行了语法调试。

```mysql
select t2.token, t2.pos-t1.pos from
(select pos, fk_sentence_id from WordInvertedIndex where token="任务") t1
LEFT JOIN
(select pos, token, fk_sentence_id from WordInvertedIndex) t2
on t1.fk_sentence_id=t2.fk_sentence_id
where t1.pos>t2.pos-5 and t1.pos<t2.pos+5
```

此时还非常慢，取决于中心词token的不同，时间从30秒到1分钟不等。

考虑添加token的索引，以提高上面代码中第二句select的效率。添加索引大概需要15分钟，属于完全能够接受的范围。添加之后，检索时间大概能够减少到15～20秒。

查了些关于性能优化的文档，除了select…where…，还有join…on…也需要使用索引来加速。因此添加了对于fk_sentence_id的索引。添加这个索引的时间大概是40分钟，在全语料上做也不是不能接受。此时的检索时间被减少到了28ms左右。达到了满意的性能。（但是fk_document_id就不加了，现在看来意义不大）

其实这个需求还可以只用倒排索引把句子都取出来，然后放在服务器上做统计，但是现在看完全用mysql的方案性能足够，暂时先作为报告提交了。

后续的操作也同理，可以在mysql上通过group by来统计词语并计算pmi，也可以在服务器上做。在决定了算法和展示内容后决定。以下是统计共现的代码，需要时间3秒。

```mysql
select token, count(*) as cnt from
(select t2.token, t2.pos-t1.pos from
(select pos, fk_sentence_id from WordInvertedIndex where token="任务") t1
LEFT JOIN
(select pos, token, fk_sentence_id from WordInvertedIndex) t2
on t1.fk_sentence_id=t2.fk_sentence_id
where t1.pos>t2.pos-5 and t1.pos<t2.pos+5) t3
group by token order by cnt desc
```

```
任务	42845
的	28689
，	23407
。	13543
完成	7019
是	6361
和	4477
、	4202
了	3365
一	2827
项	2827
艰巨	2511
主要	2361
工作	2198
在	2106
重要	1992
执行	1646
建设	1432
要	1415
...
```

